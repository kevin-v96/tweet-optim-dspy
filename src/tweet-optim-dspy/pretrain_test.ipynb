{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Research Intern Trial Notebook\n",
    "\n",
    "Thank you so much for taking the time to go through this notebook! We are looking for an ambitious, creative and intelligent person to join our team as a research intern.\n",
    "\n",
    "Your main tasks in the job will include:\n",
    "- Creating evals for creative writing use cases such as tweet or email writing\n",
    "- Testing different optimizers to figure out what prompts and models give the best outputs\n",
    "- Log each of your experiments and extract insights from them\n",
    "- Generalize the outcomes of your experiments to actionable insights for the company.\n",
    "- Experiments can include things such as: changing automated prompt engineering (DSPy) hyperparameters, fine-tuning experiments, splitting tasks into multiple steps, RAG, experimenting with different input or output variables, etc. Your creativity is most valued here, what else can we do to improve the quality of LLM outputs?\n",
    "- Reading papers and staying up-to-date with the latest new models and LLM techniques.\n",
    "- Daily reports of experiments and new insights you gained (this can be things that you tried and that didn't lead to improvements, so we know what to avoid in the future too).\n",
    "\n",
    "Not every use case is possible yet today with AI. We do not have AGI yet. But we can figure out what's possible today, and prepare for a future where models get better and better. Over time, more and more use cases will become available to us.\n",
    "\n",
    "At Pretrain we help our users train AI workflows for their specific use case. They don't need any code or prompts or even AI knowledge. All they need is some examples of what they want the AI to do. It is working well for several use cases already, and your job is to help us expand the set of possible use cases.\n",
    "\n",
    "The ideal person for this job is curious and comfortable with uncertain outcomes. Nobody knows whether a single experiment is going to work. There will be periods where it's hard to come by new improvements, but we have to keep trying.\n",
    "\n",
    "If we like working together and you show great growth throughout your time at the company, you are eligible to become an AI lead which comes with a substantial salary increase compared to the intern position.\n",
    "\n",
    "Now, let's get started with the task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training A Personal Tweet Writer\n",
    "\n",
    "You are given a dataset of 300 business-related tweets.\n",
    "\n",
    "We have created a baseline AI that creates new tweets based on the examples from the dataset.\n",
    "\n",
    "Your task is to:\n",
    "1) Create an evaluation metric that measures the quality of the tweets\n",
    "2) Create an AI system that creates better outputs according to your evaluation metric.\n",
    "\n",
    "Your AI system should show a clear improvement compared to the baseline. \n",
    "\n",
    "When you have finished your task, please record a short video detailing how you approached this task:\n",
    "- What did you try? Why did you try those things?\n",
    "- What ended up working and what didn't?\n",
    "- How did you chose your evaluation metric? \n",
    "- What % improvement did you get?\n",
    "- What are the strengths and weaknesses of your approach?\n",
    "- What ideas do you have for improving the outputs further if you had more time and resources?\n",
    "\n",
    "A key principle of our company to keep in mind for this task:\n",
    "Scaling human judgement is at the core of Pretrain. Our AI outputs are only as good as the customer says they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "Resources to get you started:\n",
    "\n",
    "DSPy:\n",
    "https://x.com/lateinteraction/status/1777098439832293593\n",
    "https://github.com/stanfordnlp/dspy/blob/main/examples/tweets/tweet_metric.py\n",
    "\n",
    "Alternative, Adalflow:\n",
    "https://adalflow.sylph.ai/tutorials/evaluation.html\n",
    "\n",
    "Any out of the box thinking is also appreciated!\n",
    "\n",
    "Just like in the real job, there aren't really any rules for what frameworks or strategies you should use. Whatever you can do to improve LLM outputs is fair game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/hormozi_tweets.jsonl', 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# make a list of 300 tweets\n",
    "tweets = [item['tweet'] for item in data][:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Tweet Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "random_tweets = random.sample(tweets, 10)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Past Tweets:\n",
    "{random_tweets}\n",
    "\n",
    "Create a new tweet based on the past tweets.\n",
    "\"\"\"\n",
    "\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "def generate_tweet(prompt):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates tweets similar to past tweets from the user.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=280,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip().lower()\n",
    "\n",
    "# Create a new tweet\n",
    "new_tweet = generate_tweet(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"success isn\\'t about never hitting a low point; it\\'s about recognizing that those moments are opportunities to push through while others quit. remember, every setback is just a setup for your comeback. ðŸ’ª\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
